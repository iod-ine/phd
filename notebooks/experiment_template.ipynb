{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b836b-62ae-478f-8eff-bced7c9a85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606db710-8341-4014-a3aa-f1df6105d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture setup_cell_output\n",
    "\n",
    "\n",
    "def clone_phd_repo(github_token: str) -> None:\n",
    "    repo_url = f\"https://iod-ine:{github_token}@github.com/iod-ine/phd.git\"\n",
    "    subprocess.run([\"git\", \"clone\", repo_url])\n",
    "    sys.path.insert(0, \"phd\")\n",
    "\n",
    "\n",
    "if (working_dir := pathlib.Path.cwd().as_posix()).startswith(\"/Users\"):\n",
    "    ENVIRONMENT = \"local\"\n",
    "    data_dir = \"../data/interim/synthetic_forest\"\n",
    "    accelerator = \"cpu\"  # mpu (Apple Silicon GPU) does not work for torch_cluster.fps()\n",
    "    num_workers = 11\n",
    "\n",
    "    import dotenv\n",
    "\n",
    "    assert dotenv.load_dotenv()\n",
    "\n",
    "elif working_dir.startswith(\"/kaggle\"):\n",
    "    ENVIRONMENT = \"Kaggle\"\n",
    "    data_dir = \"data\"\n",
    "    accelerator = \"gpu\"\n",
    "    num_workers = 3\n",
    "\n",
    "    # For Kaggle, the notebook that builds wheels for torch-cluster and torch-scatter\n",
    "    # needs to be attached as input. It's called \"torch-scatter & torch-cluster wheels\"\n",
    "    !pip install --upgrade laspy lazrs mlflow lightning torch_geometric\n",
    "    !pip install --no-index --find-links /kaggle/input/torch-scatter-torch-cluster-wheels/ torch_scatter torch_cluster\n",
    "\n",
    "    import kaggle_secrets\n",
    "\n",
    "    # The notebooks needs to be manually granted access to the secrets through the menu\n",
    "    secrets = kaggle_secrets.UserSecretsClient()\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = secrets.get_secret(\"mlflow-uri\")\n",
    "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = secrets.get_secret(\"mlflow-username\")\n",
    "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = secrets.get_secret(\"mlflow-password\")\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = secrets.get_secret(\"kaggle-username\")\n",
    "    os.environ[\"KAGGLE_KEY\"] = secrets.get_secret(\"kaggle-key\")\n",
    "\n",
    "    clone_phd_repo(github_token=secrets.get_secret(\"github-token\"))\n",
    "\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "elif working_dir.startswith(\"/content\"):\n",
    "    ENVIRONMENT = \"Colab\"\n",
    "    data_dir = \"data\"\n",
    "    accelerator = \"gpu\"\n",
    "\n",
    "    !pip install mlflow laspy lazrs lightning torch_geometric torchinfo python-dotenv\n",
    "    !pip install https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_cluster-1.6.3%2Bpt24cu121-cp310-cp310-linux_x86_64.whl\n",
    "    !pip install https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "    from google.colab import userdata\n",
    "\n",
    "    # The notebooks needs to be manually granted access to the secrets through the menu\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = userdata.get(\"mlflow-uri\")\n",
    "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = userdata.get(\"mlflow-username\")\n",
    "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = userdata.get(\"mlflow-password\")\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"kaggle-username\")\n",
    "    os.environ[\"KAGGLE_KEY\"] = userdata.get(\"kaggle-key\")\n",
    "\n",
    "    clone_phd_repo(github_token=userdata.get(\"github-token\"))\n",
    "\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "elif working_dir.startswith(\"/home/jupyter/work/resources\"):\n",
    "    ENVIRONMENT = \"DataSphere\"\n",
    "    data_dir = \"../data/interim/synthetic_forest\"\n",
    "    accelerator = \"gpu\"\n",
    "\n",
    "    sys.path.insert(0, \"phd\")\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(\"Could not determine where the notebook is running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87c916-ca67-47f9-b155-0f265769e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tempfile\n",
    "from typing import Optional\n",
    "\n",
    "import dotenv\n",
    "import laspy\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torchinfo\n",
    "from torch import nn\n",
    "\n",
    "import src.clouds\n",
    "import src.visualization.clouds\n",
    "from src.datasets import SyntheticForest\n",
    "from src.models.pointnet import PointNet2TreeSegmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb13b2-390f-4bc1-93f4-2aba22dad753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2TreeSegmentorModule(L.LightningModule):\n",
    "    \"\"\"A PointNet++ tree segmentor lightning module.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Create a new LitPointNet2TreeSegmentor instance.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.pointnet = PointNet2TreeSegmentor(num_features=4)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):  # noqa: ARG002\n",
    "        \"\"\"Process a single batch of the training dataset and return the loss.\"\"\"\n",
    "        pred = self.pointnet(batch)\n",
    "        loss = nn.functional.mse_loss(pred.squeeze(), batch.y.float())\n",
    "        per_batch_max_index, _ = torch_scatter.scatter_max(\n",
    "            src=batch.y,\n",
    "            index=batch.batch,\n",
    "        )\n",
    "        number_of_trees = (per_batch_max_index + 1).sum()\n",
    "        self.log(\"loss/train\", loss.item() / number_of_trees)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):  # noqa: ARG002\n",
    "        \"\"\"Process a single batch of the validation dataset and return the loss.\"\"\"\n",
    "        pred = self.pointnet(batch)\n",
    "        loss = nn.functional.mse_loss(pred.squeeze(), batch.y.float())\n",
    "        per_batch_max_index, _ = torch_scatter.scatter_max(\n",
    "            src=batch.y,\n",
    "            index=batch.batch,\n",
    "        )\n",
    "        number_of_trees = (per_batch_max_index + 1).sum()\n",
    "        self.validation_step_outputs.append(loss / number_of_trees)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Process the results of the validation epoch.\"\"\"\n",
    "        average_loss = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"loss/val\", average_loss)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Set up and return the optimizers.\"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=self.parameters(),\n",
    "            lr=1e-3,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer=optimizer,\n",
    "            step_size=3,\n",
    "            gamma=0.5,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f913e28-0416-472e-838f-eaea06a46430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticForestDataModule(L.LightningDataModule):\n",
    "    \"\"\"A data module for the synthetic forest dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        batch_size: int,\n",
    "        random_seed: int = 42,\n",
    "        train_samples: int = 100,\n",
    "        val_samples: int = 20,\n",
    "        test_samples: int = 20,\n",
    "        trees_per_sample: int = 50,\n",
    "        height_threshold: float = 2.0,\n",
    "        dx: float = 5.0,\n",
    "        dy: float = 5.0,\n",
    "        xy_noise_mean: float = 0.0,\n",
    "        xy_noise_std: float = 1.0,\n",
    "        las_features: Optional[list[str]] = None,\n",
    "    ):\n",
    "        \"\"\"Create a new SyntheticForestDataModule instance.\"\"\"\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = torch_geometric.transforms.Compose(\n",
    "            [\n",
    "                torch_geometric.transforms.NormalizeScale(),\n",
    "                torch_geometric.transforms.NormalizeFeatures(),\n",
    "            ]\n",
    "        )\n",
    "        self.val_transform = self.transform\n",
    "        self.dataset_params = {\n",
    "            \"root\": self.data_dir,\n",
    "            \"random_seed\": random_seed,\n",
    "            \"train_samples\": train_samples,\n",
    "            \"val_samples\": val_samples,\n",
    "            \"test_samples\": test_samples,\n",
    "            \"trees_per_sample\": trees_per_sample,\n",
    "            \"height_threshold\": height_threshold,\n",
    "            \"dx\": dx,\n",
    "            \"dy\": dy,\n",
    "            \"xy_noise_mean\": xy_noise_mean,\n",
    "            \"xy_noise_std\": xy_noise_std,\n",
    "            \"las_features\": las_features,\n",
    "        }\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare the data for setup (download, tokenize, etc.) on one device.\"\"\"\n",
    "        SyntheticForest(**self.dataset_params)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        \"\"\"Prepare the data for training (split, transform, etc.) on all devices.\"\"\"\n",
    "        if stage == \"fit\":\n",
    "            self.train = SyntheticForest(\n",
    "                split=\"train\",\n",
    "                **self.dataset_params,\n",
    "                transform=self.transform,\n",
    "            )\n",
    "            self.val = SyntheticForest(\n",
    "                split=\"val\",\n",
    "                **self.dataset_params,\n",
    "                transform=self.val_transform,\n",
    "            )\n",
    "\n",
    "        if stage == \"test\":\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Set up and return the train data loader.\"\"\"\n",
    "        return torch_geometric.loader.DataLoader(\n",
    "            dataset=self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Set up and return the validation data loader.\"\"\"\n",
    "        return torch_geometric.loader.DataLoader(\n",
    "            dataset=self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"Set up and return the test data loader.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        \"\"\"Set up and return the prediction data loader.\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a40d37-a80b-48d5-95b3-58fe5d2a3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = L.pytorch.loggers.MLFlowLogger(\n",
    "    tracking_uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "    experiment_name=\"synthetic_forest_only\",\n",
    "    tags={\n",
    "        \"environment\": ENVIRONMENT,\n",
    "    },\n",
    "    log_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff15917-bbfe-47a2-b2e8-167fac605cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    GPU_AVAILABLE = True\n",
    "    !nvidia-smi > nvidia_smi.txt\n",
    "    mlflow.log_artifact(run_id=logger.run_id, local_path=\"nvidia_smi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1556c94-4b42-4045-94cc-3f2e8d5d8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_cell_output.stdout:\n",
    "    with open(\"setup.stdout.txt\", \"w\") as f:\n",
    "        f.write(setup_cell_output.stdout)\n",
    "    mlflow.log_artifact(run_id=logger.run_id, local_path=\"setup.stdout.txt\")\n",
    "\n",
    "if setup_cell_output.stderr:\n",
    "    with open(\"setup.stderr.txt\", \"w\") as f:\n",
    "        f.write(setup_cell_output.stderr)\n",
    "    mlflow.log_artifact(run_id=logger.run_id, local_path=\"setup.stderr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fbf0c2-c1bd-4af9-b0ff-ce8c6a379985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointNet2TreeSegmentorModule()\n",
    "\n",
    "data = SyntheticForestDataModule(\n",
    "    data_dir=\"data/raw/synthetic_forest\",\n",
    "    batch_size=1,\n",
    "    trees_per_sample=9,\n",
    "    random_seed=43,\n",
    "    dx=4,\n",
    "    dy=4,\n",
    "    xy_noise_std=2,\n",
    ")\n",
    "\n",
    "mlflow.log_params(run_id=logger.run_id, params=data.dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74971ba0-00db-4bde-8588-d2bf9c697e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = torchinfo.summary(model)\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    summary_file = f\"{tmp}/model_summary.txt\"\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        f.write(str(summary))\n",
    "    mlflow.log_artifact(run_id=logger.run_id, local_path=summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e8c6e-73a8-4695-93b3-6cf8c5b123d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    fast_dev_run=False,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=50,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=5,\n",
    "    accumulate_grad_batches=1,\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[\n",
    "        L.pytorch.callbacks.EarlyStopping(\n",
    "            monitor=\"loss/val\",\n",
    "            mode=\"min\",\n",
    "            patience=3,\n",
    "        ),\n",
    "        L.pytorch.callbacks.ModelCheckpoint(\n",
    "            monitor=\"loss/val\",\n",
    "            mode=\"min\",\n",
    "            dirpath=\"checkpoints/\",\n",
    "            filename=\"{epoch}-{loss/val:.2f}\",\n",
    "            save_last=True,\n",
    "            save_top_k=1,\n",
    "            every_n_epochs=1,\n",
    "        ),\n",
    "        L.pytorch.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916ae7f-0df1-401d-9c8e-587da532e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15412655-da33-4768-a374-e024492541e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data.val[0]\n",
    "example[\"batch\"] = torch.zeros_like(example.y)\n",
    "\n",
    "model = model.pointnet.to(\"cuda\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(example.to(\"cuda\"))\n",
    "\n",
    "las = src.clouds.pyg_data_to_las(example.cpu())\n",
    "las.add_extra_dim(laspy.ExtraBytesParams(name=\"pred\", type=np.float32))\n",
    "las[\"pred\"][:] = pred.cpu().squeeze().numpy()\n",
    "las.write(\"example_prediction.laz\")\n",
    "mlflow.log_artifact(run_id=logger.run_id, local_path=\"example_prediction.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9ec9f-34f0-4188-8ab6-323eb129cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = src.visualization.clouds.scatter_point_cloud_3d(\n",
    "    las.xyz,\n",
    "    color=las[\"pred\"],\n",
    ")\n",
    "logger.experiment.log_figure(\n",
    "    run_id=logger.run_id,\n",
    "    figure=ax.figure,\n",
    "    artifact_file=\"example_prediction.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66551f-7d44-4bcd-876d-e446079acca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENVIRONMENT == \"Kaggle\":\n",
    "    print(\"Cleaning up.\")\n",
    "    !rm -rf phd data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
